{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweets Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUjEojB_5Vyg"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT2hatQZIhBi"
      },
      "source": [
        "# Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwO0iK1q5jQv"
      },
      "source": [
        "os.environ['BEARER_TOKEN'] = 'AAAAAAAAAAAAAAAAAAAAAPprQwEAAAAATVpkccH9wayqAHIchStFOxPDcVQ%3DxCDU7ucO06tFk0iipxUTURwSYy5KGmruzXFEajWjHwyqUVgDry'\n",
        "os.environ['CONSUMER_KEY'] = 'Se8VbnexMEOSbem7C4ddQfiKb'\n",
        "os.environ['CONSUMER_SECRET'] = 'DFwM5bOREWODkobpxYrOveXALgE0xb28sNmJVfiljqoHw0BtPv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVFZf1Gn5kvn"
      },
      "source": [
        "def auth():\n",
        "    return os.environ.get(\"BEARER_TOKEN\")\n",
        "\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
        "    return headers\n",
        "\n",
        "def connect_to_endpoint(url, headers, params):\n",
        "    try:\n",
        "      response = requests.request(\"GET\", url, headers=headers, params=params)\n",
        "      print(\"status code: \", response.status_code)\n",
        "      if response.status_code != 200:\n",
        "          raise Exception(\n",
        "              \"Request returned an error: {} {}\".format(\n",
        "                  response.status_code, response.text\n",
        "              )\n",
        "          )\n",
        "    except:\n",
        "        print(\"Timeout: sleep for 15 minutes and try again\")\n",
        "        time.sleep(15 * 60)\n",
        "        response = requests.request(\"GET\", url, headers=headers, params=params)\n",
        "    return response.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dutyU2dCwZEO"
      },
      "source": [
        "# Tweets API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCpDu_tpwced"
      },
      "source": [
        "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/sample-realtime/overview\n",
        "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets\n",
        "# https://developer.twitter.com/en/docs/twitter-api/v1/tweets/filter-realtime/api-reference/post-statuses-filter\n",
        "# https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmXW4SMWIeTS"
      },
      "source": [
        "# Tweets Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIXq01P-IVoh"
      },
      "source": [
        "def tweets(keyword, token_flag = False, max_id = \"\"):\n",
        "    if (token_flag):\n",
        "        bearer_token = auth()\n",
        "        url = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
        "        params = {\"q\":keyword, \"count\":\"100\", \"max_id\":max_id, \"include_entities\":1}\n",
        "        headers = create_headers(bearer_token)\n",
        "        json_response = connect_to_endpoint(url, headers, params)\n",
        "        return(json_response)\n",
        "    else:\n",
        "        bearer_token = auth()\n",
        "        url = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
        "        params = {\"q\":keyword, \"count\":\"100\"}\n",
        "        headers = create_headers(bearer_token)\n",
        "        json_response = connect_to_endpoint(url, headers, params)\n",
        "        return(json_response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHG4l0cJKvUs"
      },
      "source": [
        "keywords = [\"Telkomsel\", \"myXLCare\", \"IndosatCare\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhEWlNa3LLlT",
        "outputId": "6ed64367-69c2-4680-f300-950e55c7f74c"
      },
      "source": [
        "df_tweets = pd.DataFrame()\n",
        "\n",
        "for key in keywords:\n",
        "    data = tweets(key)\n",
        "\n",
        "    # mengatasi error apabila user private\n",
        "    if (('errors' in data) or (data['search_metadata']['count'] == 0)):\n",
        "        continue\n",
        "\n",
        "    # mengubah data json menjadi dataframe\n",
        "    df = pd.DataFrame(data['statuses']).pop(\"text\")\n",
        "\n",
        "    # mengambil next tweet berdasar next token\n",
        "    while ((len(df)<1000) & (data['search_metadata']['count']==100)):\n",
        "        next_results = data['search_metadata']['next_results']\n",
        "        max_id = next_results.split('=', 1)[1].split('&', 1)[0]\n",
        "\n",
        "        data = tweets(key, True, max_id)\n",
        "\n",
        "        # apabila ternyata tweet telah habis dan data masih kurang dari 1000 (pembatalan request)\n",
        "        if (data['search_metadata']['count']==0):\n",
        "            break\n",
        "\n",
        "        df_temp = pd.DataFrame(data['statuses']).pop(\"text\")\n",
        "\n",
        "        df = pd.concat([df, df_temp])\n",
        "        clear_output(wait=True)\n",
        "        print('Total data - {}: '.format(key), len(df), '/ 1000')\n",
        "\n",
        "    # penggabungan df\n",
        "    df_tweets=pd.concat([df_tweets, df])  \n",
        "    clear_output(wait=True)\n",
        "\n",
        "    # mengubah dataframe jadi csv\n",
        "    df_tweets.to_csv(r'{}.csv'.format(key), index = False)\n",
        "\n",
        "    # reset dataframe\n",
        "    df_tweets = df_tweets.iloc[0:0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data - IndosatCare:  1000 / 1000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}